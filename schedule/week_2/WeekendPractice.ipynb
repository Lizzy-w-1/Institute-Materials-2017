{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1009588"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile = 'C:/Users/ewilliamson.FOLGER2000/GitWorkspace/Institute-Materials-2017/schedule/week_2/UntonPractice/Print-UntonCorres-lres.txt'\n",
    "mytext = open(myfile).read()\n",
    "#print(mytext)\n",
    "len(mytext)  #length ie number of characters\n",
    "#'wiU' in mytext  #boolean test for whether string is in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199897"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import nltk\n",
    "nltk.word_tokenize(mytext)\n",
    "#%pprint    #turn off/on pretty printing (which prints things one per line)\n",
    "mytokens = nltk.word_tokenize(mytext)   #makes new item, list of tokens\n",
    "len(mytokens)  #length ie number of word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15235"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfreq = nltk.FreqDist(mytokens)\n",
    "#frequency distribution, ie number of times words appear\n",
    "#function that creates dictionary, key= unique word, value= number of times\n",
    "wfreq['the'] #call this on a given word\n",
    "#nltk.FreqDist(mytokens)['the']   #ie same as above\n",
    "len(wfreq)  #ie number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 12584),\n",
       " ('the', 9411),\n",
       " ('of', 6889),\n",
       " ('.', 6815),\n",
       " ('to', 6504),\n",
       " ('and', 5875),\n",
       " ('I', 2701),\n",
       " (';', 2453),\n",
       " ('in', 2287),\n",
       " ('his', 1910)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfreq.most_common(10)  #most_common is a function: call it on the word frequency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6875\n"
     ]
    }
   ],
   "source": [
    "sentcount = wfreq['.'] + wfreq['?'] + wfreq['!']\n",
    "print(sentcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171412"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytokens_nosym = [item for item in mytokens if item.isalnum()]\n",
    "len(mytokens_nosym)\n",
    "# ie number of tokens excluding punc. New list made by list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"n't\".isalnum() #problem: we've excluded words w punctuation in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You', 'haven', 't', 'seen', 'Star', 'Wars']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using regex instead...\n",
    "import re\n",
    "sent = \"You haven't seen Star Wars...?\"\n",
    "re.findall(r'\\w+', sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'\\w+', mytext)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
